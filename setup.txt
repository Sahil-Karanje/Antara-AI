===========================
A. SYSTEM SETUP (WINDOWS)
===========================

1Ô∏è‚É£  Install Python 3.10+  (from https://www.python.org/downloads/)
    ‚úÖ Check it works:  python --version

2Ô∏è‚É£  Create a virtual environment:
    python -m venv venv
    venv\Scripts\activate

3Ô∏è‚É£  Install dependencies:
    pip install -r requirements.txt

4Ô∏è‚É£  Install FFmpeg (for Whisper audio decoding)
    - Download from: https://ffmpeg.org/download.html
    - Add FFmpeg `bin` folder to your PATH.
    ‚úÖ Test:  ffmpeg -version

5Ô∏è‚É£  Install Java (for LanguageTool if used later)
    - Download from: https://adoptium.net/temurin/releases/
    ‚úÖ Test:  java -version

6Ô∏è‚É£  Install Node.js (for your main backend)
    - Download from: https://nodejs.org/en/download
    ‚úÖ Test:  node -v  &&  npm -v

7Ô∏è‚É£  Install Ollama (local LLM runtime)
    - Download from: https://ollama.com/download
    - Once installed, run:
      ollama serve
    - In another terminal, pull model:
      ollama pull gemma3:4b

    ‚úÖ Test the model:
      ollama run gemma3:4b
      (type something, check if it replies)


===========================
B. PROJECT SETUP
===========================

1Ô∏è‚É£  Clone your repo:
    git clone <your_repo_url>
    cd <project_folder>

2Ô∏è‚É£  Create `.env` file in the root (same directory as your FastAPI files):
    ```
    OLLAMA_URL=http://localhost:11434
    OLLAMA_MODEL=gemma3:4b
    ```

3Ô∏è‚É£  Start FastAPI services:

    # Speech-to-Text (Whisper)
    uvicorn stt_service:app --reload --port 5001

    # Grammar/LLM (Ollama)
    uvicorn grammar_service:app --reload --port 5003

    # Text-to-Speech (gTTS)
    uvicorn tts_service:app --reload --port 5002

4Ô∏è‚É£  Start Node.js backend:
    cd src/server
    npm install
    npm run dev

5Ô∏è‚É£  Test endpoints individually (via Postman):

    üëâ STT:
       POST http://localhost:5001/stt
       form-data ‚Üí key: audio, value: (upload .wav file)

    üëâ Grammar/LLM:
       POST http://localhost:5003/grammar
       form-data ‚Üí text: "I win a match against a tough opponent."
                     username: "Sahil"

    üëâ TTS:
       POST http://localhost:5002/tts
       form-data ‚Üí text: "Hello Sahil, great job today!"

6Ô∏è‚É£  To verify the conversation pipeline:
    Use your Node controller (handleConversation.js)
    It will internally call:
      STT ‚Üí Grammar (Ollama) ‚Üí TTS


===========================
C. OPTIONAL AUTOMATION
===========================

üëâ To make setup 1-click on Windows:
   Create a file named `setup.bat` with:

   @echo off
   echo Activating virtual environment...
   call venv\Scripts\activate
   echo Installing Python dependencies...
   pip install -r requirements.txt
   echo Starting Ollama service...
   start ollama serve
   echo Pulling model gemma3:4b...
   ollama pull gemma3:4b
   echo Setup complete! ‚úÖ

   pause


===========================
D. QUICK CHECKLIST
===========================

‚úÖ Python installed  
‚úÖ FFmpeg installed  
‚úÖ Java (optional for LanguageTool)  
‚úÖ Node.js installed  
‚úÖ Ollama installed and model pulled  
‚úÖ FastAPI services running (5001‚Äì5003)  
‚úÖ Node backend running (5000)  
‚úÖ .env file present with OLLAMA_URL + OLLAMA_MODEL  

===========================